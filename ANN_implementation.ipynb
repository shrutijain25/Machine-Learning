{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zz7BcGCftH8P",
        "outputId": "4b9fb32e-4e04-4aee-d206-c8ae4795c19b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from keras.datasets import mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_images.shape\n",
        "len(train_labels)\n",
        "train_labels\n",
        "test_images.shape\n",
        "len(test_labels)\n",
        "test_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQzBoqcItNJ8",
        "outputId": "4b86c639-7c43-4d83-d790-fb6c1ef95cd7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Network Architecture"
      ],
      "metadata": {
        "id": "vlCRf9d2umTw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "network = models.Sequential()\n",
        "# Dense(32) is a fully-connected layer with 32 hidden units.\n",
        "# in the first layer, you must specify the expected input data shape :\n",
        "# here, 28 X 28=784 -dimensional vectors.\n",
        "network.add(layers.Dense(32, activation='sigmoid', input_shape=(28 * 28, )))\n",
        "network.add(layers.Dense(8, activation='sigmoid'))\n",
        "network.add(layers.Dense(10, activation='softmax'))\n",
        "network.summary()\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-7uqGdVtYo8",
        "outputId": "44e644ce-2c10-4b11-a6ea-5fbf46562166"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 32)                25120     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 8)                 264       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                90        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25474 (99.51 KB)\n",
            "Trainable params: 25474 (99.51 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Compilation Step"
      ],
      "metadata": {
        "id": "7JX2dFJRuhwM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "network.compile(optimizer='sgd',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "PbfAh-6ptoEM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparing the Image Data\n",
        "\n"
      ],
      "metadata": {
        "id": "GzpIavUOudsd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype('float32') / 255.\n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype('float32') / 255.\n",
        ""
      ],
      "metadata": {
        "id": "WW6PQXM-tsa7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparing the Labels"
      ],
      "metadata": {
        "id": "Bxztw3y8uY67"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "train_labels = to_categorical(train_labels)\n",
        "train_labels\n",
        "test_labels = to_categorical(test_labels)\n",
        "test_labels\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gb84whqStvZX",
        "outputId": "d602108d-6015-4c19-a410-5387a79c5f99"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 1., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training and Testing"
      ],
      "metadata": {
        "id": "EDgER7i-uWy8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "network.fit(train_images, train_labels, epochs=160, batch_size=512)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufS1Mv3jtzj3",
        "outputId": "321d33b6-9866-4b47-992d-1ba4a33ae475"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/160\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 2.3270 - accuracy: 0.1584\n",
            "Epoch 2/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 2.3054 - accuracy: 0.1708\n",
            "Epoch 3/160\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 2.2935 - accuracy: 0.1768\n",
            "Epoch 4/160\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 2.2855 - accuracy: 0.2315\n",
            "Epoch 5/160\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 2.2792 - accuracy: 0.2691\n",
            "Epoch 6/160\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 2.2735 - accuracy: 0.2851\n",
            "Epoch 7/160\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 2.2680 - accuracy: 0.3025\n",
            "Epoch 8/160\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 2.2624 - accuracy: 0.3150\n",
            "Epoch 9/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 2.2564 - accuracy: 0.3079\n",
            "Epoch 10/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 2.2501 - accuracy: 0.3283\n",
            "Epoch 11/160\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 2.2434 - accuracy: 0.3430\n",
            "Epoch 12/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 2.2361 - accuracy: 0.3474\n",
            "Epoch 13/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 2.2284 - accuracy: 0.3569\n",
            "Epoch 14/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 2.2200 - accuracy: 0.3654\n",
            "Epoch 15/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 2.2110 - accuracy: 0.3786\n",
            "Epoch 16/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 2.2013 - accuracy: 0.3848\n",
            "Epoch 17/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 2.1909 - accuracy: 0.3939\n",
            "Epoch 18/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 2.1797 - accuracy: 0.3971\n",
            "Epoch 19/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 2.1677 - accuracy: 0.4021\n",
            "Epoch 20/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 2.1548 - accuracy: 0.4058\n",
            "Epoch 21/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 2.1411 - accuracy: 0.4102\n",
            "Epoch 22/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 2.1266 - accuracy: 0.4158\n",
            "Epoch 23/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 2.1113 - accuracy: 0.4163\n",
            "Epoch 24/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 2.0951 - accuracy: 0.4184\n",
            "Epoch 25/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 2.0781 - accuracy: 0.4220\n",
            "Epoch 26/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 2.0605 - accuracy: 0.4236\n",
            "Epoch 27/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 2.0421 - accuracy: 0.4262\n",
            "Epoch 28/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 2.0231 - accuracy: 0.4286\n",
            "Epoch 29/160\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 2.0037 - accuracy: 0.4283\n",
            "Epoch 30/160\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 1.9838 - accuracy: 0.4320\n",
            "Epoch 31/160\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 1.9635 - accuracy: 0.4349\n",
            "Epoch 32/160\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 1.9429 - accuracy: 0.4384\n",
            "Epoch 33/160\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 1.9222 - accuracy: 0.4408\n",
            "Epoch 34/160\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 1.9013 - accuracy: 0.4440\n",
            "Epoch 35/160\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 1.8804 - accuracy: 0.4482\n",
            "Epoch 36/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.8595 - accuracy: 0.4501\n",
            "Epoch 37/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.8387 - accuracy: 0.4549\n",
            "Epoch 38/160\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 1.8180 - accuracy: 0.4574\n",
            "Epoch 39/160\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 1.7975 - accuracy: 0.4629\n",
            "Epoch 40/160\n",
            "118/118 [==============================] - 1s 5ms/step - loss: 1.7772 - accuracy: 0.4662\n",
            "Epoch 41/160\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 1.7571 - accuracy: 0.4710\n",
            "Epoch 42/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.7372 - accuracy: 0.4752\n",
            "Epoch 43/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.7177 - accuracy: 0.4807\n",
            "Epoch 44/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.6985 - accuracy: 0.4858\n",
            "Epoch 45/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.6795 - accuracy: 0.4906\n",
            "Epoch 46/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.6610 - accuracy: 0.4968\n",
            "Epoch 47/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.6427 - accuracy: 0.5021\n",
            "Epoch 48/160\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 1.6248 - accuracy: 0.5085\n",
            "Epoch 49/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.6072 - accuracy: 0.5142\n",
            "Epoch 50/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.5900 - accuracy: 0.5208\n",
            "Epoch 51/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.5731 - accuracy: 0.5265\n",
            "Epoch 52/160\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 1.5566 - accuracy: 0.5323\n",
            "Epoch 53/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.5403 - accuracy: 0.5399\n",
            "Epoch 54/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.5244 - accuracy: 0.5464\n",
            "Epoch 55/160\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 1.5089 - accuracy: 0.5529\n",
            "Epoch 56/160\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 1.4936 - accuracy: 0.5588\n",
            "Epoch 57/160\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 1.4786 - accuracy: 0.5650\n",
            "Epoch 58/160\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 1.4639 - accuracy: 0.5702\n",
            "Epoch 59/160\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 1.4495 - accuracy: 0.5759\n",
            "Epoch 60/160\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 1.4354 - accuracy: 0.5822\n",
            "Epoch 61/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.4215 - accuracy: 0.5883\n",
            "Epoch 62/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.4078 - accuracy: 0.5939\n",
            "Epoch 63/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.3944 - accuracy: 0.5994\n",
            "Epoch 64/160\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 1.3813 - accuracy: 0.6051\n",
            "Epoch 65/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.3683 - accuracy: 0.6104\n",
            "Epoch 66/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.3555 - accuracy: 0.6160\n",
            "Epoch 67/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.3430 - accuracy: 0.6211\n",
            "Epoch 68/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.3306 - accuracy: 0.6256\n",
            "Epoch 69/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.3184 - accuracy: 0.6306\n",
            "Epoch 70/160\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 1.3064 - accuracy: 0.6354\n",
            "Epoch 71/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.2946 - accuracy: 0.6404\n",
            "Epoch 72/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.2830 - accuracy: 0.6442\n",
            "Epoch 73/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.2715 - accuracy: 0.6488\n",
            "Epoch 74/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.2601 - accuracy: 0.6534\n",
            "Epoch 75/160\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 1.2489 - accuracy: 0.6581\n",
            "Epoch 76/160\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 1.2379 - accuracy: 0.6618\n",
            "Epoch 77/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.2270 - accuracy: 0.6659\n",
            "Epoch 78/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.2162 - accuracy: 0.6704\n",
            "Epoch 79/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.2056 - accuracy: 0.6755\n",
            "Epoch 80/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.1951 - accuracy: 0.6794\n",
            "Epoch 81/160\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 1.1848 - accuracy: 0.6834\n",
            "Epoch 82/160\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 1.1745 - accuracy: 0.6869\n",
            "Epoch 83/160\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 1.1644 - accuracy: 0.6913\n",
            "Epoch 84/160\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 1.1545 - accuracy: 0.6941\n",
            "Epoch 85/160\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 1.1446 - accuracy: 0.6980\n",
            "Epoch 86/160\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 1.1349 - accuracy: 0.7010\n",
            "Epoch 87/160\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 1.1253 - accuracy: 0.7045\n",
            "Epoch 88/160\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 1.1159 - accuracy: 0.7076\n",
            "Epoch 89/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.1066 - accuracy: 0.7110\n",
            "Epoch 90/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.0974 - accuracy: 0.7136\n",
            "Epoch 91/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.0883 - accuracy: 0.7168\n",
            "Epoch 92/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.0793 - accuracy: 0.7201\n",
            "Epoch 93/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.0705 - accuracy: 0.7226\n",
            "Epoch 94/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.0617 - accuracy: 0.7256\n",
            "Epoch 95/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.0531 - accuracy: 0.7274\n",
            "Epoch 96/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.0446 - accuracy: 0.7308\n",
            "Epoch 97/160\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 1.0363 - accuracy: 0.7331\n",
            "Epoch 98/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.0280 - accuracy: 0.7353\n",
            "Epoch 99/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.0199 - accuracy: 0.7390\n",
            "Epoch 100/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 1.0119 - accuracy: 0.7415\n",
            "Epoch 101/160\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 1.0040 - accuracy: 0.7436\n",
            "Epoch 102/160\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.9962 - accuracy: 0.7456\n",
            "Epoch 103/160\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.9885 - accuracy: 0.7482\n",
            "Epoch 104/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.9810 - accuracy: 0.7513\n",
            "Epoch 105/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.9735 - accuracy: 0.7538\n",
            "Epoch 106/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.9662 - accuracy: 0.7556\n",
            "Epoch 107/160\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.9589 - accuracy: 0.7581\n",
            "Epoch 108/160\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 0.9518 - accuracy: 0.7603\n",
            "Epoch 109/160\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.9448 - accuracy: 0.7626\n",
            "Epoch 110/160\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 0.9379 - accuracy: 0.7640\n",
            "Epoch 111/160\n",
            "118/118 [==============================] - 1s 7ms/step - loss: 0.9311 - accuracy: 0.7664\n",
            "Epoch 112/160\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.9244 - accuracy: 0.7682\n",
            "Epoch 113/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.9178 - accuracy: 0.7698\n",
            "Epoch 114/160\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.9113 - accuracy: 0.7720\n",
            "Epoch 115/160\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.9049 - accuracy: 0.7741\n",
            "Epoch 116/160\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.8986 - accuracy: 0.7759\n",
            "Epoch 117/160\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.8924 - accuracy: 0.7774\n",
            "Epoch 118/160\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.8863 - accuracy: 0.7791\n",
            "Epoch 119/160\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.8802 - accuracy: 0.7809\n",
            "Epoch 120/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.8743 - accuracy: 0.7826\n",
            "Epoch 121/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.8685 - accuracy: 0.7846\n",
            "Epoch 122/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.8628 - accuracy: 0.7858\n",
            "Epoch 123/160\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.8571 - accuracy: 0.7874\n",
            "Epoch 124/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.8516 - accuracy: 0.7885\n",
            "Epoch 125/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.8461 - accuracy: 0.7903\n",
            "Epoch 126/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.8407 - accuracy: 0.7921\n",
            "Epoch 127/160\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.8353 - accuracy: 0.7933\n",
            "Epoch 128/160\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.8301 - accuracy: 0.7947\n",
            "Epoch 129/160\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.8250 - accuracy: 0.7963\n",
            "Epoch 130/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.8199 - accuracy: 0.7972\n",
            "Epoch 131/160\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.8149 - accuracy: 0.7990\n",
            "Epoch 132/160\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.8099 - accuracy: 0.8000\n",
            "Epoch 133/160\n",
            "118/118 [==============================] - 1s 11ms/step - loss: 0.8051 - accuracy: 0.8012\n",
            "Epoch 134/160\n",
            "118/118 [==============================] - 1s 11ms/step - loss: 0.8003 - accuracy: 0.8027\n",
            "Epoch 135/160\n",
            "118/118 [==============================] - 1s 10ms/step - loss: 0.7955 - accuracy: 0.8040\n",
            "Epoch 136/160\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.7909 - accuracy: 0.8054\n",
            "Epoch 137/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.7863 - accuracy: 0.8065\n",
            "Epoch 138/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.7818 - accuracy: 0.8078\n",
            "Epoch 139/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.7773 - accuracy: 0.8091\n",
            "Epoch 140/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.7729 - accuracy: 0.8098\n",
            "Epoch 141/160\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.7686 - accuracy: 0.8114\n",
            "Epoch 142/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.7643 - accuracy: 0.8123\n",
            "Epoch 143/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.7601 - accuracy: 0.8133\n",
            "Epoch 144/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.7559 - accuracy: 0.8149\n",
            "Epoch 145/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.7518 - accuracy: 0.8159\n",
            "Epoch 146/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.7477 - accuracy: 0.8173\n",
            "Epoch 147/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.7437 - accuracy: 0.8181\n",
            "Epoch 148/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.7398 - accuracy: 0.8190\n",
            "Epoch 149/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.7359 - accuracy: 0.8204\n",
            "Epoch 150/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.7320 - accuracy: 0.8210\n",
            "Epoch 151/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.7282 - accuracy: 0.8224\n",
            "Epoch 152/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.7245 - accuracy: 0.8230\n",
            "Epoch 153/160\n",
            "118/118 [==============================] - 1s 4ms/step - loss: 0.7207 - accuracy: 0.8241\n",
            "Epoch 154/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.7171 - accuracy: 0.8253\n",
            "Epoch 155/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.7135 - accuracy: 0.8262\n",
            "Epoch 156/160\n",
            "118/118 [==============================] - 0s 4ms/step - loss: 0.7099 - accuracy: 0.8273\n",
            "Epoch 157/160\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.7063 - accuracy: 0.8280\n",
            "Epoch 158/160\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.7028 - accuracy: 0.8287\n",
            "Epoch 159/160\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.6994 - accuracy: 0.8296\n",
            "Epoch 160/160\n",
            "118/118 [==============================] - 1s 6ms/step - loss: 0.6960 - accuracy: 0.8304\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e1dad961540>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ]
}
